{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuzRAl0a4biRL7jssNUqbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pandatoey/LAB229351/blob/main/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_208424Lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 4: Gradient Verification for Ridge Regression"
      ],
      "metadata": {
        "id": "_K5pagVautog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad\n",
        "\n",
        "#1.Generate synthetic data\n",
        "key = jax.random.PRNGKey(0)\n",
        "\n",
        "X = jax.random.normal(key, (50, 5))   # X ∈ R^{50×5}\n",
        "y = jax.random.normal(key, (50,))     # y ∈ R^{50}\n",
        "beta = jax.random.normal(key, (5,))   # β ∈ R^{5}\n",
        "lam = 10.0                            # λ = 10\n",
        "\n",
        "#2.Ridge Regression loss\n",
        "def ridge_loss(beta, X, y, lam):\n",
        "    r = X @ beta - y\n",
        "    return r.T @ r + lam * (beta.T @ beta)\n",
        "\n",
        "#3.หาค่า gradient จากฟังก์ชัน jax โดยตรง\n",
        "jax_grad = grad(ridge_loss)(beta, X, y, lam)\n",
        "\n",
        "#4.หาค่า gradient จากสูตรคณิตศาสตร์ ∇β​f(β)=2(XTXβ−XTy+λβ)\n",
        "def ridge_grad_analytic(beta, X, y, lam):\n",
        "    return 2 * (X.T @ (X @ beta - y) + lam * beta)\n",
        "\n",
        "#5.Analytic gradient\n",
        "analytic_grad = ridge_grad_analytic(beta, X, y, lam)\n",
        "\n",
        "#6.Compare\n",
        "print(\"JAX gradient:\", jax_grad)\n",
        "print(\"Analytic gradient:\", analytic_grad)\n",
        "print(\"Gradients match:\",\n",
        "      jnp.allclose(jax_grad, analytic_grad)) #ค่า gradient ที่ได้จาก jax กับ จากสูตรคำนวณมีค่าใกล้เคียงกัน"
      ],
      "metadata": {
        "id": "ncqxCDdmu7sb",
        "outputId": "1762f195-5c22-48f1-fcdd-e9653d7bf15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX gradient: [152.26129  233.75662  -22.530704   1.699074  35.291744]\n",
            "Analytic gradient: [152.26132   233.75667   -22.530706    1.6990726  35.29174  ]\n",
            "Gradients match: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 5: MLE Verification via Gradient Checking"
      ],
      "metadata": {
        "id": "YqjXxi6ivZ-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad\n",
        "\n",
        "# 1. Generate exponential data\n",
        "key = jax.random.PRNGKey(42)\n",
        "lambda_true = 4.0 #ค่าพารามิเตอร์จริงคือ 4\n",
        "x = jax.random.exponential(key, (100,)) / lambda_true\n",
        "\n",
        "# 2. Analytic MLE\n",
        "lambda_hat = 1.0 / jnp.mean(x)\n",
        "\n",
        "# 3. Negative Log-Likelihood\n",
        "def nll(lam, x):\n",
        "    return -jnp.sum(jnp.log(lam) - lam * x)\n",
        "\n",
        "# 4. Gradient of NLL\n",
        "nll_grad = grad(nll)\n",
        "\n",
        "# 5. Evaluate gradient at analytic MLE\n",
        "grad_at_mle = nll_grad(lambda_hat, x)\n",
        "\n",
        "print(\"True lambda:\", lambda_true)\n",
        "print(\"Estimated lambda_hat:\", lambda_hat)\n",
        "print(\"Gradient at lambda_hat:\", grad_at_mle)"
      ],
      "metadata": {
        "id": "IMRFDN_5vcK5",
        "outputId": "35f9c7b5-8cc1-4c5a-f27f-04e6805d5769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True lambda: 4.0\n",
            "Estimated lambda_hat: 4.1560264\n",
            "Gradient at lambda_hat: 1.9073486e-06\n"
          ]
        }
      ]
    }
  ]
}